{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Spatial Projection Conversion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Enough is enough.  Every time I need to convert a CRS from one projection to another, I find myself scouring the internet for some way of making it easier to convert an entire shapefile at once.  Ultimately, each time I write some quick and dirty method, housed within the analysis of interest.  The time has come to keep this operation in one place, thereby potentially improving upon the code with each time I use it.  Perhaps this will help with making it more robust, and may lead to ... (gasp) my first class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Basic data manipulation\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "#Spatial data manipulation\n",
      "import fiona\n",
      "from shapely.geometry import mapping,shape,Polygon\n",
      "import pyproj\n",
      "import geopandas as gp\n",
      "\n",
      "#Set print width\n",
      "pd.set_option('line_width',120)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The basic strategy is to convert each individual coordinate pair within each Polygon (or LineString or whatever) from one projection to another, and then recombine the converted points into new Polygons.  This collection is then deposited into a new shapefile, and all is right with the world."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Input"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal is to generate a generic workflow.  This has two implications:\n",
      "\n",
      "1. The file information (location and name) ought to be set as globals; and,\n",
      "2. To ensure that a given shapefile exits with the same attribute data with which entered, there must be a dynamic method of grabbing and storing all fields.\n",
      "\n",
      "First, what is our file location?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shp_dir='/home/choct155/ora_public/dc_shp/'\n",
      "shp_file='CensusBG_Areas.shp'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us define a function that converts this shapefile into a [pandas](http://pandas.pydata.org/) DataFrame (DF)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shp2df(f):\n",
      "    '''Function takes a shapefile as an input and returns a DF with all attribute information and a 'geometry'\n",
      "    variable that houses the spatial elements in the first position.  In the second position the metadata is\n",
      "    returned.'''\n",
      "    #Open shapefile\n",
      "    shps=fiona.open(f)\n",
      "    \n",
      "    #Create container for attribute data\n",
      "    attr_data=[]\n",
      "    \n",
      "    #Create container for shapes\n",
      "    shape_list=[]\n",
      "    \n",
      "    #For each feature...\n",
      "    for shp in shps:\n",
      "        #...create a field container for feature-specific attributes...\n",
      "        field_list=[]\n",
      "        #...and for each field...\n",
      "        for field in shp['properties']:\n",
      "            #...capture each field value in the field list...\n",
      "            field_list.append(shp['properties'][field])\n",
      "        #...then dump the record in the attribute list...\n",
      "        attr_data.append(field_list)\n",
      "        #...and capture the associated shape\n",
      "        shape_list.append(shape(shp['geometry']))\n",
      "        \n",
      "    #Capture field labels\n",
      "    field_labels=shps.meta['schema']['properties'].keys()\n",
      "    \n",
      "    \n",
      "    #Construct DF from attribute data\n",
      "    sp_df=pd.DataFrame(attr_data,columns=field_labels)\n",
      "    \n",
      "    #Integrate shapes\n",
      "    sp_df['geom_in']=pd.Series(shape_list,index=sp_df.index)\n",
      "    \n",
      "    return [sp_df,shps.meta]\n",
      "\n",
      "#Capture shape DF\n",
      "shp_df=shp2df(shp_dir+shp_file)[0]\n",
      "\n",
      "#Capture shape metadata\n",
      "shp_meta=shp2df(shp_dir+shp_file)[1]\n",
      "\n",
      "print shp_df\n",
      "shp_meta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                                            NAME                                            geom_in\n",
        "0                                ROCK CREEK EAST  POLYGON ((399254.6683124974370003 142129.39631...\n",
        "1                                ROCK CREEK WEST  POLYGON ((395645.3709999993443489 139271.08537...\n",
        "2                                UPPER NORTHEAST  POLYGON ((399950.6563749983906746 139098.26881...\n",
        "3                                       MID-CITY  POLYGON ((396002.9578749984502792 138508.60212...\n",
        "4                                 NEAR NORTHWEST  POLYGON ((399114.7783125042915344 137676.52400...\n",
        "5  LOWER ANACOSTIA WATERFRONT AND NEAR SOUTHWEST  POLYGON ((400956.6071875020861626 133347.56231...\n",
        "6                    FAR NORTHEAST AND SOUTHEAST  POLYGON ((404620.6771875023841858 132881.73299...\n",
        "7                             CENTRAL WASHINGTON  POLYGON ((397914.5028750002384186 137230.60762...\n",
        "8                                   CAPITOL HILL  POLYGON ((401565.3331250026822090 134508.02050...\n",
        "9                    FAR SOUTHEAST AND SOUTHWEST  POLYGON ((400765.3203750029206276 129034.25187...\n",
        "\n",
        "[10 rows x 2 columns]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "{'crs': {u'datum': u'NAD83',\n",
        "  u'lat_0': 37.6666666667,\n",
        "  u'lat_1': 38.3,\n",
        "  u'lat_2': 39.45,\n",
        "  u'lon_0': -77,\n",
        "  u'no_defs': True,\n",
        "  u'proj': u'lcc',\n",
        "  u'units': u'm',\n",
        "  u'x_0': 400000,\n",
        "  u'y_0': 0},\n",
        " 'driver': u'ESRI Shapefile',\n",
        " 'schema': {'geometry': 'Polygon',\n",
        "  'properties': OrderedDict([(u'NAME', 'str')])}}"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Conversion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In pursuit of a generic function to automate this process, let us be explicit about the micro-level mechanics, and examine how we convert a point from one projection to another.  We can use the first point of the shape above to demonstrate the idea."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Capture test coordinate (assume Polygon, but allow for LineStrings and Points\n",
      "try:\n",
      "    test_coord=shp_df['geom_in'][0].exterior.coords[0]\n",
      "except:\n",
      "    test_coord=shp_df['geom_in'][0].coords[0]\n",
      "    \n",
      "test_coord"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "(399254.66831249744, 142129.39631250128)"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We must identify two projection schemes:  the input scheme and our desired output.  With respect to the former, we can pull this directly from the file.  The latter must be defined explicitly.  (This whole thing would be rather pointless otherwise.)  We are free to define the desired projection via a proj4 string or via [EPSG](http://www.epsg.org/) codes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proj2_in='+init=EPSG:4326'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have made these choices, we need to instantiate **`pyproj`** objects with these parameters via the **`pyproj.Proj()`** method.  The **`pyproj.Proj()`** method is the critical preamble to the conversion process.  It structures the data in a way that the actual conversion method, **`pyproj.transform()`**, can process.  Further, if we had untransformed coordinates, the **`pyproj.Proj()`** can autonomously convert them to projected coordinates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proj1=pyproj.Proj(shp_meta['crs'])\n",
      "proj2=pyproj.Proj(proj2_in)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are now in a position to pass our test coordinate pair back and forth across projections."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '***ORIGINAL***\\n',test_coord\n",
      "print '\\n\\n***CONVERTED FROM PROJECTION 1 TO PROJECTION 2***'\n",
      "convert=pyproj.transform(proj1,proj2,test_coord[0],test_coord[1])\n",
      "print convert\n",
      "print '\\n\\n***CONVERTED BACK TO THE ORIGINAL PROJECTION***'\n",
      "inverse=pyproj.transform(proj2,proj1,convert[0],convert[1])\n",
      "print inverse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "***ORIGINAL***\n",
        "(399254.66831249744, 142129.39631250128)\n",
        "\n",
        "\n",
        "***CONVERTED FROM PROJECTION 1 TO PROJECTION 2***\n",
        "(-77.00859799962357, 38.94705999998761)\n",
        "\n",
        "\n",
        "***CONVERTED BACK TO THE ORIGINAL PROJECTION***\n",
        "(399254.6683124979, 142129.39631247666)\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These same operations will work on a pair of arrays as well (an array of `x` coordinates and an array of `y` coordinates).  Now we can loop through the coordinate arrays of each feature, converting coordinates with the quickness."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def poly_proj(df,proj1_in,proj2_in):\n",
      "    #Structure data for conversion\n",
      "    proj1=pyproj.Proj(proj1_in)\n",
      "    proj2=pyproj.Proj(proj2_in)\n",
      "    \n",
      "    #Create a container for the transformed features\n",
      "    feature_list=[]\n",
      "    \n",
      "    #For each feature...\n",
      "    for ftr in list(df['geom_in']):\n",
      "        #...capture the coordinate array in two lists...\n",
      "        x_in=[x[0] for x in ftr.exterior.coords]\n",
      "        y_in=[x[1] for x in ftr.exterior.coords]\n",
      "        #...convert the coordinate array to the new projection...\n",
      "        xy_out=pyproj.transform(proj1,proj2,x_in,y_in)\n",
      "        #...define the newly projected feature...\n",
      "        poly_out=Polygon(zip(xy_out[0],xy_out[1]))\n",
      "        #...and throw it in the list\n",
      "        feature_list.append(poly_out)\n",
      "        \n",
      "    #Generate new geometry variable\n",
      "    df['geometry']=pd.Series(feature_list,index=df.index)\n",
      "    \n",
      "    return df[[x for x in df.columns if x != 'geom_in']]\n",
      "    \n",
      "shp_df_out=poly_proj(shp_df,shp_meta['crs'],proj2_in)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Output"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to output this data so we can actually use it.  I initially thought I might write my own routine for this portion, but why try to improve on a great product like [geopandas](http://geopandas.org/).  This package (which is a must use for anyone doing spatial/statistical analysis) already has a nice write method called **`GeoDataFrame.to_file`**, so why don't we run with that?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gp.GeoDataFrame(shp_df_out).to_file(shp_dir+'Google_'+shp_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That being said, let's say we just really needed the flexibility offered by low-level control with fiona.  Here is a function that dynamically builds records from a DF."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "#Define function to output records with an arbitrary number of fields\n",
      "def df2fiona_out(df):\n",
      "    #Create record dictionary\n",
      "    rec_dict={}\n",
      "    \n",
      "    #For each record...\n",
      "    for i in range(len(df)):\n",
      "        #...capture the geometry...\n",
      "        rec_dict.update({'geometry':mapping(df['geometry'][i])})\n",
      "        #...create containers for field specific labels and data...\n",
      "        field_list=[]\n",
      "        field_data_list=[]\n",
      "        #...and for each field that is not geometry...\n",
      "        for fld in [x for x in df.columns if x != 'geometry']:\n",
      "            #...populate the field containers with labels and data....\n",
      "            field_list.append(unicode(fld))\n",
      "            field_data_list.append(df[fld][i])\n",
      "        #...then bind the field information in a dict and update rec_dict...\n",
      "        rec_dict.update({'properties':dict(zip(field_list,field_data_list))})\n",
      "        output.write(rec_dict)\n",
      "    print 'NUMBER OF RECORDS WRITTEN:',str(i+1)\n",
      "    output.close()\n",
      "    \n",
      "#Capture schema and crs from \n",
      "with fiona.open(dem_dir+'DCdem_by_area.shp','r') as source:\n",
      "    source_schema=source.schema\n",
      "    source_crs=source.crs\n",
      "    \n",
      "#Create new schema (in case old keys in 'properties' are cut off)\n",
      "##Match up schema keys\n",
      "schema_map=dict(zip(sorted(source_schema['properties'].keys()),sorted([x for x in data.columns if x != 'geometry'])))\n",
      "##Create new schema\n",
      "schema_out={'geometry':'Polygon',\n",
      "            'properties':OrderedDict([(schema_map[k],v) for k,v in source_schema['properties'].items()])}\n",
      "    \n",
      "with fiona.open(dem_dir+'DCdem_by_area.geojson','w','GeoJSON',schema_out,source_crs) as output:\n",
      "    df2fiona_out(data)\n",
      "    \n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}